{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# M8-L1 Problem 1\n",
    "\n",
    "In this problem you will solve for $\\frac{\\partial L}{\\partial W_2}$ and $\\frac{\\partial L}{\\partial W_1}$ for a neural network with two input features, a hidden layer with 3 nodes, and a single output. You will use the sigmoid activation function on the hidden layer. You are provided an input sample $x_0$, the current weights $W_1$ and $W_2$, and the ground truth value for the sample, $t = -2$\n",
    "\n",
    "$L=\\frac{1}{2}e^Te$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "x0 = np.array([[-2], [-6]])\n",
    "\n",
    "W1 = np.array([[-2, 1],[3, 8],[-12, 7]])\n",
    "W2 = np.array([[-11, 2, 5]])\n",
    "\n",
    "t = np.array([[-2]])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define activation function and its derivative\n",
    "\n",
    "First define functions for the sigmoid activation functions, as well as its derivative:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "def sigmoid(x):\n",
    "    return 1/(1 + np.exp(-x))\n",
    "\n",
    "def d_sigmoid(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Forward propagation\n",
    "\n",
    "Using your activation function, compute the output of the network $y$ using the sample $x_0$ and the provided weights $W_1$ and $W_2$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "hidden_input = np.dot(W1, x0)\n",
    "\n",
    "hidden_output = sigmoid(hidden_input)\n",
    "\n",
    "output = np.dot(W2, hidden_output)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Backpropagation\n",
    "\n",
    "Using your calculated value of $y$, the provided value of $t$, your $\\sigma$ and $\\sigma'$ function, and the provided weights $W_1$ and $W_2$, compute the gradients $\\frac{\\partial L}{\\partial W_2}$ and $\\frac{\\partial L}{\\partial W_1}$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dL_dW1:  [[ 1.59095673e+00  4.77287018e+00]\n",
      " [-9.73264513e-24 -2.91979354e-23]\n",
      " [-1.04899214e-07 -3.14697641e-07]]\n",
      "dL_dW2:  [[8.21031503e-02 2.43316128e-24 1.04899215e-08]]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE GOES HERE\n",
    "e = output - t\n",
    "L = 1/2 * np.dot(e, e)\n",
    "\n",
    "dL_dy = e\n",
    "dL_dW2 = dL_dy * hidden_output.T\n",
    "\n",
    "dL_dhidden_output = dL_dy * W2.T\n",
    "dL_dhidden_input = dL_dhidden_output * d_sigmoid(hidden_input)\n",
    "dL_dW1 = np.dot(dL_dhidden_input, x0.T)\n",
    "\n",
    "print(\"dL_dW1: \", dL_dW1)\n",
    "print(\"dL_dW2: \", dL_dW2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
